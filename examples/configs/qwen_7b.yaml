# Qwen 7B Model Configuration
# Smaller model for testing and development

model:
  name: "Qwen/Qwen2.5-7B-Instruct"
  dtype: "bfloat16"
  device: 0

dataset:
  path: "dataset/Math/train"
  max_seq_len: 1024
  num_workers: 4

training:
  batch_size: 148
  gradient_accumulation_steps: 1
  num_steps: 1000
  learning_rate: 2.0e-5
  weight_decay: 0.01
  max_grad_norm: 1.0
  seed: 42

optimizer:
  type: "deepspeed_adam"
  beta1: 0.9
  beta2: 0.999
  eps: 1.0e-8

memory:
  checkpoint_interval: 4
  num_grad_slabs: 12

logging:
  log_interval: 1
  enable_timing: true
